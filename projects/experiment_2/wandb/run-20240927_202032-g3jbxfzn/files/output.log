GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/joro/src/ai-engineer/.venv/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name      | Type             | Params | Mode
-------------------------------------------------------
0 | model     | SimpleCNN        | 421 K  | train
1 | criterion | CrossEntropyLoss | 0      | train
-------------------------------------------------------
421 K     Trainable params
0         Non-trainable params
421 K     Total params
1.687     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
Epoch 1: 100%|â–ˆ| 860/860 [00:11<00:00, 77.25it/s, v_num=xfzn, train_loss_step=0.107, train_acc_step=0.958, val_loss
/Users/joro/src/ai-engineer/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.
/Users/joro/src/ai-engineer/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.
                                                                                                                   
`Trainer.fit` stopped: `max_epochs=2` reached.
